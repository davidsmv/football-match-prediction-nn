# Copilot Instructions

## Project Overview

Football match prediction project that scrapes Premier League fixture data from FBRef and will eventually use neural networks for match outcome prediction. Currently in early stage — the scraping pipeline works, prediction model is not yet built.

## Architecture

- **`app/services/fbref_data_scraper.py`** — Core scraper using `undetected-chromedriver` + Selenium to bypass FBRef's bot detection. Renders JavaScript-heavy pages, then parses fixture tables with BeautifulSoup/lxml. Outputs a DataFrame with columns: week, day, date, time, home, score, away, attendance, venue, referee, match_report.
- **`app/services/notebooks/`** — Jupyter notebooks for data exploration (`data.ipynb` loads scraped CSVs, `soccerdata.ipynb` experiments with the `soccerdata` library).
- **`app/data/`** — Scraped output (CSV files, raw HTML). Not the source of truth — regenerated by running the scraper.
- **`app/main.py`** — Entry point (currently empty, intended for orchestration).

## Setup & Commands

```bash
# Install dependencies (uses pip-compile for pinning)
pip install -r requirements.txt

# Add a new dependency
# 1. Add to requirements.in
# 2. Run: pip-compile requirements.in

# Run the scraper
python app/services/fbref_data_scraper.py
```

Requires Chrome installed locally — `undetected-chromedriver` manages the ChromeDriver binary. The `version_main` parameter in `FbrefDataScraper.__init__` must match the installed Chrome major version.

## Conventions

- Dependencies are managed with `pip-compile`: add packages to `requirements.in`, then compile to `requirements.txt`. Do not edit `requirements.txt` by hand.
- Data paths use `pathlib.Path` relative to the module location (`Path(__file__).parent.parent / "data"`).
- Logging uses the standard `logging` module with `__name__` loggers.
